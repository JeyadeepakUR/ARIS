# ğŸ§  ARIS â€“ AI Research Intelligence System

ğŸš€ Revolutionizing how researchers explore, analyze, and synthesize knowledge.  
Built for the **CodeMate Hackathon** using Python, Streamlit, and AI-powered NLP.

---

## ğŸŒŸ Unique Selling Points (USP)

- **Advanced Document Intelligence**  
  Entity extraction, methodology detection, semantic structure parsing, and automated quality scoring.

- **Knowledge Graph Construction**  
  Dynamic, weighted concept mapping with research gap detection and author collaboration networks.

- **Systematic Literature Analysis**  
  AI-powered thematic clustering, temporal trend mapping, and methodological distribution tracking.

- **Research Insights Engine**  
  Actionable intelligence for future research directions and methodology recommendations.

- **Interactive Dashboards**  
  Visual analytics of trends, impact scores, networks, and concept evolution.

- **Production-Grade Design**  
  Modular architecture, model switching, system configuration tools, database optimization, and backup support.

---

## ğŸ—ï¸ Project Structure

```

root/
â”‚
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ main.py                # Entrypoint wrapper (for platforms using `python main.py`)
â”œâ”€â”€ research\_agent.py       # Orchestrator: embeddings, retrieval, reasoning
â”œâ”€â”€ requirements.txt        # Pinned dependencies
â”œâ”€â”€ analysis/               # Specialized analysis modules
â”‚   â”œâ”€â”€ document\_processing.py
â”‚   â”œâ”€â”€ impact\_scoring.py
â”‚   â”œâ”€â”€ knowledge\_graph.py
â”‚   â”œâ”€â”€ literature\_review\.py
â”‚   â””â”€â”€ trends.py
â””â”€â”€ utils/                  # Support code
â”œâ”€â”€ file\_readers.py
â”œâ”€â”€ visualization.py
â””â”€â”€ config.py

````

---

## âš™ï¸ Installation

Clone and set up the environment:

```bash
git clone https://github.com/your-username/aris.git
cd aris

# Create environment
conda create -n aris python=3.10 -y
conda activate aris

# Install dependencies
pip install -r requirements.txt

# If using spaCy NLP
python -m spacy download en_core_web_sm
````

### Core Dependencies

* `streamlit` â€“ web UI
* `sentence-transformers` â€“ embeddings
* `faiss-cpu` (or `faiss-gpu`) â€“ vector search
* `transformers` â€“ local LLM reasoning
* `pypdf`, `python-docx` â€“ document parsing
* `spacy`, `textstat` â€“ NLP & readability metrics
* `networkx`, `pyvis` â€“ knowledge graphs
* `matplotlib`, `plotly`, `pandas` â€“ visualizations
* `reportlab` â€“ PDF export

---

## ğŸš€ Usage

### Run the app

```bash
# Local development
streamlit run app.py

# On CodeMate platform
python main.py
```

### Workflow

1.  Upload research documents (`.pdf`, `.docx`, `.txt`, `.md`, `.csv`).
2. The system automatically:

   * Extracts semantic sections (abstract, methodology, results, limitations).
   * Generates embeddings and indexes locally with FAISS.
   * Builds knowledge graphs, impact scores, and trend maps.
   * Performs retrieval + reasoning using local NLP models.
3. Explore results in interactive dashboards.
4. Export findings as PDF/Markdown research reports.

---


## ğŸ“‚ Document Ingestion Supported Formats

* `.txt`, `.md`, `.csv`, `.json`
* `.pdf` (via PyPDF2 / pypdf)
* `.docx` (via python-docx)

Large PDFs are chunked automatically to prevent spaCy memory errors.

---

## ğŸ§ª Extensibility

* **Swap embedding model**

  ```python
  from sentence_transformers import SentenceTransformer
  embedder = SentenceTransformer("all-mpnet-base-v2")
  ```

* **Swap reasoning model**

  ```python
  from transformers import AutoModelForCausalLM, AutoTokenizer
  tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-7b-instruct")
  model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-7b-instruct")
  ```

* **Add new analysis**: create a module in `analysis/` and hook it into `research_agent.py`.

---

## ğŸŒ Hosting

### Streamlit Community Cloud

- Push repo to GitHub.
- Deploy via [streamlit.io/cloud](https://streamlit.io/cloud).
- Set entrypoint to `app.py`.
- Every GitHub push redeploys automatically.

### Self-host (EC2 / VPS / Docker)

Run with:

```bash
streamlit run app.py
```

Use `pm2`, `systemd`, or Docker to keep the service alive.

---
## ğŸ› ï¸ Troubleshooting

* **spaCy error (text too long)** â†’ increase `nlp.max_length` or chunk input.
* **Large model download slow** â†’ switch to smaller embeddings (`all-mpnet-base-v2`).
* **Scanned PDFs** â†’ require OCR (`pytesseract + pdf2image`).
* **CodeMate IDE issues** â†’ remove heavy folders before upload.

---

## ğŸ“œ License

MIT License â€“ free to use and extend with credit.

---

## ğŸ‘¨â€ğŸ’» Authors

Team ARIS â€“ CodeMate Hackathon 2025